{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nBJZNyqGSHUK"
      },
      "source": [
        "# Extra Credit: DCGAN for QuickDraw *Cat* Sketches (Fast Version)\n",
        "\n",
        "This notebook trains a DCGAN to generate cat sketches using a subset of the QuickDraw dataset. It is fast (5,000 images, 5 epochs) and suitable for extra credit experiments. Edit for more epochs or categories as needed!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H5wEEaxvSHUN"
      },
      "source": [
        "### Install all required Python libraries\n",
        "This cell installs the necessary packages for deep learning, plotting, and data loading."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hXyzou1KSHUO"
      },
      "source": [
        "# Install dependencies for PyTorch, torchvision, numpy, matplotlib, requests, tqdm\n",
        "!pip install torch torchvision numpy matplotlib requests tqdm --quiet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vnb4ej7VSHUP"
      },
      "source": [
        "## 1. Download and Explore the QuickDraw Cat Dataset\n",
        "This cell downloads the 'cat' QuickDraw category if needed, loads the npy file, and displays 10 random examples."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IpVV4MvaSHUQ"
      },
      "source": [
        "import numpy as np  # Import numpy for numerical operations and loading npy files\n",
        "import matplotlib.pyplot as plt  # For plotting images and figures\n",
        "import requests  # For downloading the dataset\n",
        "import os  # For file operations like checking if file exists\n",
        "\n",
        "cat_url = \"https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/cat.npy\"  # URL to download cat QuickDraw data\n",
        "filename = \"cat.npy\"  # Name for the local file to store data\n",
        "if not os.path.exists(filename):  # Check if file already exists\n",
        "    print(\"Downloading cat dataset...\")  # Inform user\n",
        "    r = requests.get(cat_url)  # Download file from url\n",
        "    with open(filename, \"wb\") as f:  # Open file in write-binary mode\n",
        "        f.write(r.content)  # Write the content to the file\n",
        "    print(\"Download complete.\")  # Inform user\n",
        "\n",
        "images = np.load(filename)  # Load the npy file into a numpy array\n",
        "print(f\"Loaded {images.shape[0]} cat images of shape {images.shape[1:]}\")  # Show how many images loaded\n",
        "\n",
        "# Use only a subset for speed\n",
        "images = images[:5000]  # Keep first 5000 images for fast training\n",
        "print(f\"Using subset: {images.shape[0]} images\")  # Display subset size\n",
        "\n",
        "plt.figure(figsize=(10,2))  # Make a wide figure for showing 10 images\n",
        "for i in range(10):  # Loop through first 10 images\n",
        "    plt.subplot(1,10,i+1)  # Make a row of 10 subplots\n",
        "    plt.imshow(images[i].reshape(28,28), cmap='gray')  # Show image reshaped to 28x28\n",
        "    plt.axis('off')  # Hide axes\n",
        "plt.suptitle(\"Sample QuickDraw Cat Sketches\")  # Add a title above all images\n",
        "plt.show()  # Display the figure"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0PEZ5azSHUS"
      },
      "source": [
        "## 2. Prepare Dataset for PyTorch\n",
        "This cell wraps the numpy image data into a PyTorch Dataset and DataLoader, normalizing pixel values to [-1, 1]."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDMwhQf3SHUS"
      },
      "source": [
        "import torch  # Import PyTorch for deep learning\n",
        "from torch.utils.data import Dataset, DataLoader  # For creating datasets and batching\n",
        "\n",
        "class QuickDrawDataset(Dataset):  # Custom dataset for QuickDraw images\n",
        "    def __init__(self, npy_data):  # Constructor takes numpy array\n",
        "        self.data = npy_data.astype(np.float32) / 255.0  # Normalize to [0,1] float\n",
        "        self.data = (self.data - 0.5) / 0.5              # Shift to [-1,1] (needed for DCGAN)\n",
        "    def __len__(self):  # Return number of samples\n",
        "        return len(self.data)\n",
        "    def __getitem__(self, idx):  # Get one sample (as tensor)\n",
        "        img = self.data[idx].reshape(1,28,28)            # Reshape to (1, 28, 28) - 1 channel\n",
        "        return torch.tensor(img)  # Return as PyTorch tensor\n",
        "\n",
        "qd_dataset = QuickDrawDataset(images)  # Create dataset instance\n",
        "dataloader = DataLoader(qd_dataset, batch_size=64, shuffle=True, drop_last=True)  # Batch data for training"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5P3Q8kDNSHUU"
      },
      "source": [
        "## 3. Define DCGAN Generator and Discriminator\n",
        "This cell defines the generator and discriminator neural network architectures used for the DCGAN."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3kABmojSHUU"
      },
      "source": [
        "import torch.nn as nn  # Import nn for neural network layers\n",
        "\n",
        "# Define the generator network\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, nz=100, ngf=64):  # nz: latent vector size, ngf: feature maps\n",
        "        super().__init__()\n",
        "        self.main = nn.Sequential(\n",
        "            nn.ConvTranspose2d(nz, ngf*4, 7, 1, 0, bias=False), # (batch, ngf*4, 7, 7)\n",
        "            nn.BatchNorm2d(ngf*4),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(ngf*4, ngf*2, 4, 2, 1, bias=False), # (batch, ngf*2, 14, 14)\n",
        "            nn.BatchNorm2d(ngf*2),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(ngf*2, 1, 4, 2, 1, bias=False),     # (batch, 1, 28, 28)\n",
        "            nn.Tanh()  # Output in [-1,1]\n",
        "        )\n",
        "    def forward(self, input):  # Forward method\n",
        "        return self.main(input)\n",
        "\n",
        "# Define the discriminator network\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, ndf=64):  # ndf: feature maps\n",
        "        super().__init__()\n",
        "        self.main = nn.Sequential(\n",
        "            nn.Conv2d(1, ndf, 4, 2, 1, bias=False),  # (batch, ndf, 14, 14)\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(ndf, ndf*2, 4, 2, 1, bias=False),  # (batch, ndf*2, 7, 7)\n",
        "            nn.BatchNorm2d(ndf*2),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Flatten(),  # Flatten to (batch, ndf*2*7*7)\n",
        "            nn.Linear(ndf*2*7*7, 1),  # Final output layer\n",
        "            nn.Sigmoid()  # Output probability [0,1]\n",
        "        )\n",
        "    def forward(self, input):  # Forward method\n",
        "        return self.main(input)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0tZ5bC4tSHUV"
      },
      "source": [
        "## 4. Initialize Models, Loss, and Optimizers\n",
        "This cell sets up the generator and discriminator, moves them to GPU if available, and defines the optimizer and loss function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-tQxIh0DSHUW"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # Use GPU if available\n",
        "\n",
        "netG = Generator().to(device)  # Create generator and move to device\n",
        "netD = Discriminator().to(device)  # Create discriminator and move to device\n",
        "\n",
        "criterion = nn.BCELoss()  # Binary Cross Entropy loss for GANs\n",
        "optimizerD = torch.optim.Adam(netD.parameters(), lr=0.0002, betas=(0.5, 0.999))  # Adam optimizer for D\n",
        "optimizerG = torch.optim.Adam(netG.parameters(), lr=0.0002, betas=(0.5, 0.999))  # Adam optimizer for G\n",
        "\n",
        "nz = 100  # Latent vector size (input to generator)\n",
        "fixed_noise = torch.randn(16, nz, 1, 1, device=device)  # Same noise to visualize progress"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wPvhuAruSHUW"
      },
      "source": [
        "## 5. Train the DCGAN (Fast Version, 5 Epochs)\n",
        "This cell trains the DCGAN for 5 epochs. Losses are recorded, and generated samples are shown at the end."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xU2wzcEWSHUX"
      },
      "source": [
        "from tqdm.notebook import tqdm  # For progress bars\n",
        "import torchvision  # For utility functions (make_grid)\n",
        "\n",
        "num_epochs = 5  # Number of training epochs\n",
        "G_losses, D_losses, img_list = [], [], []  # Lists to store losses and generated images\n",
        "\n",
        "for epoch in range(1, num_epochs+1):  # Loop over epochs\n",
        "    for real_imgs in tqdm(dataloader, desc=f\"Epoch {epoch}/{num_epochs}\"):  # Loop over batches\n",
        "        real_imgs = real_imgs.to(device)  # Move real images to device\n",
        "        b_size = real_imgs.size(0)  # Get batch size\n",
        "        # Update Discriminator\n",
        "        netD.zero_grad()  # Zero gradients for D\n",
        "        real_labels = torch.ones(b_size, 1, device=device)  # Real label=1\n",
        "        fake_labels = torch.zeros(b_size, 1, device=device)  # Fake label=0\n",
        "        output = netD(real_imgs).view(-1, 1)  # D output for real images\n",
        "        lossD_real = criterion(output, real_labels)  # D loss on real\n",
        "        noise = torch.randn(b_size, nz, 1, 1, device=device)  # Random noise for G\n",
        "        fake_imgs = netG(noise)  # Generate fake images\n",
        "        output = netD(fake_imgs.detach()).view(-1, 1)  # D output for fake, detached to not backprop to G\n",
        "        lossD_fake = criterion(output, fake_labels)  # D loss on fake\n",
        "        lossD = lossD_real + lossD_fake  # Total D loss\n",
        "        lossD.backward()  # Backprop D\n",
        "        optimizerD.step()  # Update D params\n",
        "        # Update Generator\n",
        "        netG.zero_grad()  # Zero gradients for G\n",
        "        output = netD(fake_imgs).view(-1, 1)  # D output on fake images (not detached)\n",
        "        lossG = criterion(output, real_labels)  # G loss (wants D to think fake is real)\n",
        "        lossG.backward()  # Backprop G\n",
        "        optimizerG.step()  # Update G params\n",
        "    G_losses.append(lossG.item())  # Record generator loss\n",
        "    D_losses.append(lossD.item())  # Record discriminator loss\n",
        "    if epoch == num_epochs:  # At last epoch, visualize generated images\n",
        "        with torch.no_grad():\n",
        "            fake = netG(fixed_noise).detach().cpu()  # Generate images from fixed noise\n",
        "        img_grid = torchvision.utils.make_grid(fake, nrow=4, normalize=True)  # Make grid of 16 images\n",
        "        img_list.append(img_grid)  # Add to list\n",
        "        plt.figure(figsize=(5, 2))\n",
        "        plt.axis(\"off\")\n",
        "        plt.title(f\"Epoch {epoch} - Generated Cat Sketches\")\n",
        "        plt.imshow(np.transpose(img_grid, (1, 2, 0)), cmap=\"gray\")  # Show grid\n",
        "        plt.show()\n",
        "        print(f\"Epoch {epoch}: Generator Loss {lossG.item():.4f}, Discriminator Loss {lossD.item():.4f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y8XhwwEBSHUX"
      },
      "source": [
        "## 6. Plot Training Losses\n",
        "This cell visualizes generator and discriminator loss curves over training epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vdOi5asDSHUY"
      },
      "source": [
        "plt.figure(figsize=(8,4))  # Set figure size\n",
        "plt.plot(G_losses, label=\"Generator Loss\")  # Plot G loss\n",
        "plt.plot(D_losses, label=\"Discriminator Loss\")  # Plot D loss\n",
        "plt.xlabel(\"Epoch\")  # Label x-axis\n",
        "plt.ylabel(\"Loss\")  # Label y-axis\n",
        "plt.title(\"DCGAN Training Losses\")  # Title\n",
        "plt.legend()  # Add legend\n",
        "plt.show()  # Show plot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_S8Du-sZSHUY"
      },
      "source": [
        "## 7. Visual Comparison: Real vs. Fake Cat Sketches\n",
        "This cell displays a set of real cat sketches and generated cat sketches for visual comparison."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wKahCTFhSHUY"
      },
      "source": [
        "# Show real images\n",
        "plt.figure(figsize=(10,2))  # Set wide figure\n",
        "for i in range(10):  # Top row: real images\n",
        "    plt.subplot(2,10,i+1)\n",
        "    plt.imshow(images[i].reshape(28,28), cmap='gray')\n",
        "    plt.axis('off')\n",
        "plt.suptitle(\"Real Cat Sketches (top) vs. Fake (bottom)\")\n",
        "\n",
        "# Show generated images (from last epoch)\n",
        "with torch.no_grad():\n",
        "    fake = netG(fixed_noise).detach().cpu()\n",
        "for i in range(10):  # Bottom row: generated images\n",
        "    plt.subplot(2,10,10+i+1)\n",
        "    plt.imshow(fake[i][0], cmap='gray')\n",
        "    plt.axis('off')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OuiYHmktSHUZ"
      },
      "source": [
        "# **Discussion: Model Performance on Cat Sketches**\n",
        "\n",
        "- The DCGAN learns to draw basic cat shapes, but details (whiskers, ears, faces) may be blurry with few epochs and small dataset.\n",
        "- Cat sketches are more complex than smiley faces, so more training (epochs & data) improves results.\n",
        "- Try running longer or with all 70,000+ images for clearer, more recognizable cats.\n",
        "- You can repeat this notebook for other categories (e.g., \"house\") by changing the download URL and filename.\n",
        "\n",
        "Submit this notebook as your extra credit extension!"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": ""
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}